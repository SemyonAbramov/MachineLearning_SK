{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Assignment No. 4 (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please, write your implementation within the designated blocks:\n",
    "```python\n",
    "...\n",
    "### BEGIN Solution\n",
    "\n",
    "# >>> your solution here <<<\n",
    "\n",
    "### END Solution\n",
    "...\n",
    "```\n",
    "\n",
    "Write your theoretical derivations within such blocks:\n",
    "```markdown\n",
    "**BEGIN Solution**\n",
    "\n",
    "<!-- >>> your derivation here <<< -->\n",
    "\n",
    "**END Solution**\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\LaTeX$ in Jupyter\n",
    "Jupyter has constantly improving $\\LaTeX$ support. Below are the basic methods to\n",
    "write **neat, tidy, and well typeset** equations in your notebooks:\n",
    "* to write an **inline** equation use \n",
    "```markdown\n",
    "$ you latex equation here $\n",
    "```\n",
    "* to write an equation, that is **displayed on a separate line** use \n",
    "```markdown\n",
    "$$ you latex equation here $$\n",
    "```\n",
    "* to write a **block of equations** use \n",
    "```markdown\n",
    "\\begin{align}\n",
    "    left-hand-side\n",
    "        &= right-hand-side on line 1\n",
    "        \\\\\n",
    "        &= right-hand-side on line 2\n",
    "        \\\\\n",
    "        &= right-hand-side on the last line\n",
    "\\end{align}\n",
    "```\n",
    "The **ampersand** (`&`) aligns the equations horizontally and the **double backslash**\n",
    "(`\\\\`) creates a new line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly / outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will need to work through a modified version of\n",
    "the SVDD model (**support vector data description**) -- a model for outlier\n",
    "detection, and show some theoretical properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we have a dataset $x_1, \\ldots, x_l$ from some set $\\mathcal{X}$.\n",
    "\n",
    "We apply the kernel trick using the kernel $K \\colon \\mathcal{X} \\times \\mathcal{X}\n",
    "\\to \\mathbb{R}$ of the Hilbert space $\\bigl(\\mathcal{H}, \\langle \\cdot,\n",
    "\\cdot \\rangle\\big)$ with the feature mapping $\\phi(\\cdot)\\colon \\mathcal{X}\n",
    "\\to \\mathcal{H}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that $\\nu \\in (0, 1)$, and $C_i > 0$ with $\\sum_{i=1}^l C_i = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVDD model (kernelized) is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "    & \\underset{R, h, \\xi}{\\text{minimize}}\n",
    "      & & R + \\frac1\\nu \\sum_{i=1}^l C_i \\xi_i\n",
    "          \\,, \\\\\n",
    "    & \\text{subject to}\n",
    "      & & \\|\\phi(x_i) - h \\|^2 \\leq R + \\xi_i\n",
    "          \\,, \\\\\n",
    "    & & & \\xi_i \\geq 0\n",
    "          \\,.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (3 pt.): Can $R$ be negative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the SVDD problem with an extra constraint $R \\geq 0$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    & \\underset{R, h, \\xi}{\\text{minimize}}\n",
    "      & & R + \\frac1\\nu \\sum_{i=1}^l C_i \\xi_i\n",
    "          \\,, \\\\\n",
    "    & \\text{subject to}\n",
    "      & & \\|\\phi(x_i) - h \\|^2 \\leq R + \\xi_i\n",
    "          \\,, \\\\\n",
    "    & & & \\xi_i \\geq 0\n",
    "          \\,, \\\\\n",
    "    & & & R \\geq 0\n",
    "          \\,.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $R \\geq 0$ constraint is a nuisance.\n",
    "\n",
    "* Show, that if $(R, \\xi, h)$ has $R < 0$, then it **is not better** than a\n",
    "certain other feasible candidate $(\\hat{R}, \\hat{\\xi}, \\hat{h})$ with $\\hat{R} \\geq 0$.\n",
    "* Argue that it is, in fact, **redundant**, i.e. the problem formulations\n",
    "**with it** and **without it** have identical solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***Good explanations on SVDD are given in the [article](http://pages.cs.wisc.edu/~ching-pei/paper/svdd/svdd.pdf) and in the lecture 19 (Anomaly detection)***. \n",
    "\n",
    "Assume that $(\\hat{R}, h, \\xi)$ is optimum, where $\\hat{R} < 0$.<br>\n",
    "Let's consider $(0, h, \\xi + \\hat{R}\\textbf{e})$, where $\\textbf{e}$ is a vector of all ones. This point will be feasible because it satisfies the constraint \n",
    "\n",
    "$$ \n",
    "    0 \\le \\|\\phi(x_i) - h \\|^2 \\leq R + \\xi_i = 0 + (\\hat{R} + \\xi_i)\n",
    "$$\n",
    "\n",
    "By the conditions we have $\\nu \\in (0, 1)$, and $C_i > 0$ with $\\sum_{i=1}^l C_i = 1$. Since $\\hat{R} < 0$ then for our considered point we have \n",
    "\n",
    "$$\n",
    "    0 + \\frac{1}{\\nu}\\sum_{i=1}^{l} C_i(\\xi_i + \\hat{R}) = 0 + \\frac{1}{\\nu}\\sum_{i=1}^{l} C_i \\xi_i + \\frac{1}{\\nu} \\hat{R} \\sum_{i=1}^{l} C_i < \\frac{1}{\\nu}\\sum_{i=1}^{l} C_i \\xi_i + \\hat{R}\n",
    "$$\n",
    "\n",
    "But it is the contradiction with the assumption that $(\\hat{R}, h, \\xi)$, $\\hat{R} < 0$ is the optimal point.<br>\n",
    "So, the constraint $R \\geq 0$ is redundant, since there will be always better solution than for any $R < 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (2 pt.): Can $\\xi_i > 0$ for all $i$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Argue if $(R, \\xi, h)$ is a solution, then $\\xi_i = 0$ for at least one $i=1,\\,\\ldots,\\,l$. Let $\\bar{\\xi} = \\min_{j=1}^l \\xi_j$.\n",
    "\n",
    "**HINT** Use an argument similar to Task $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 (2 pt.): The Lagrangian and KKT conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please, write out the Lagrangian function of the problem and write out the KKT conditions\n",
    "* Lagrangian\n",
    "* the first order conditions\n",
    "* the complementary slackness conditions\n",
    "* the primal and dual constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here we consider the optimization problem\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    & \\underset{R, h, \\xi}{\\text{minimize}}\n",
    "      & & R + \\frac1\\nu \\sum_{i=1}^l C_i \\xi_i\n",
    "          \\,, \\\\\n",
    "    & \\text{subject to}\n",
    "      & & \\|\\phi(x_i) - h \\|^2 \\leq R + \\xi_i\n",
    "          \\,, \\\\\n",
    "    & & & \\xi_i \\geq 0\n",
    "          \\,.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Let's write out Lagrangian\n",
    "\n",
    "$$\n",
    "    L(R, h, \\xi, \\alpha, \\beta) = R + \\frac{1}{\\nu}\\sum_{i=1}^{l} C_i \\xi_i + \\sum_{i=1}^{l}\\alpha_i(\\|\\phi(x_i) - h\\|^{2} - R - \\xi_i) + \\sum_{i=0}^{l}\\beta_i (-\\xi_i)\n",
    "$$\n",
    "\n",
    "***KKT conditions***\n",
    "\n",
    "The first order conditions\n",
    "\n",
    "$$\n",
    "    \\nabla_{R} L = 1 - \\sum_{i=0}^{l}\\alpha_i = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\nabla_{h} L = 2\\sum_{i=0}^{l}\\alpha_{i}(\\phi(x_i) - h) = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\nabla_{\\xi} L = 0 \\to \\frac{1}{\\nu}C_{i} - \\alpha_i - \\beta_i = 0, \\quad i = 0, \\dots, l\n",
    "$$\n",
    "\n",
    "The complementary slackness conditions\n",
    "\n",
    "$$\n",
    "    \\alpha_{i} (\\| \\phi(x_i) - h \\|^{2} - R - \\xi_i) = 0, \\quad i = 1, \\dots, l\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\beta_{i} \\xi_i = 0, \\quad i = 1, \\dots, l\n",
    "$$\n",
    "\n",
    "The primal constraints\n",
    "\n",
    "$$\n",
    "    \\| \\phi(x_i) - h \\|^{2} - R - \\xi_i \\le 0, \\quad i = 1, \\dots, l\n",
    "$$\n",
    "\n",
    "$$\n",
    "    - \\xi_i \\le 0, \\quad i = 1, \\dots, l\n",
    "$$\n",
    "\n",
    "The dual constraints\n",
    "\n",
    "$$\n",
    "    \\alpha_i \\geq 0, \\quad i = 1, \\dots, l\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\beta_i \\geq 0, \\quad i = 1, \\dots, l\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 (2 pt.): Simplifying the Lagrangian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down $h$ as a function of transformed input data and dual coefficients,\n",
    "and using the first order conditions rewrite the Lagrangian in such a way, that\n",
    "it only contains dual variables and evaluations of the kernel $K(\\cdot, \\cdot)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From KKT condition $\\nabla_{h} = 2\\sum_{i=0}^{l}\\alpha_{i}(\\phi(x_i) - h) = 0$ and $1 - \\sum_{i=0}^{l}\\alpha_i = 0$\n",
    "\n",
    "$$\n",
    "    h \\sum_{i=1}^{l}\\alpha_i = \\sum_{i=1}^{l}\\alpha_{i}\\phi(x_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "    h = \\sum_{i=1}^{l}\\alpha_{i}\\phi(x_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "     L(R, h, \\xi, \\alpha, \\beta) = R + \\frac{1}{\\nu}\\sum_{i=1}^{l} C_i \\xi_i + \\sum_{i=1}^{l}\\alpha_i(\\|\\phi(x_i) - h\\|^{2} - R - \\xi_i) + \\sum_{i=0}^{l}\\beta_i (-\\xi_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "    L(R, h, \\xi, \\alpha, \\beta) = R + \\frac{1}{\\nu}\\sum_{i=1}^{l} (C_i - \\alpha_i - \\beta_i) \\xi_i + \\sum_{i=1}^{l}\\alpha_i(\\|\\phi(x_i) - h\\|^{2} - R)\n",
    "$$\n",
    "\n",
    "From KKT $ \\: \\frac{1}{\\nu}C_{i} - \\alpha_i - \\beta_i = 0$\n",
    "\n",
    "$$\n",
    "    L(R, h, \\xi, \\alpha, \\beta) = R + \\sum_{i=1}^{l}\\alpha_i(\\|\\phi(x_i) - h\\|^{2} - R)\n",
    "$$\n",
    "\n",
    "$$\n",
    "    L(R, h, \\xi, \\alpha, \\beta) = R(1 - \\sum_{i=0}^{l}\\alpha_i) + \\sum_{i=1}^{l}\\alpha_i(\\|\\phi(x_i) - h\\|^{2}) = \\sum_{i=1}^{l}\\alpha_i \\|\\phi(x_i) - h\\|^{2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\|\\phi(x_i) - h\\|^{2} = \\|\\phi\\|^{2} - 2\\langle \\phi(x_i), h\\rangle + \\|h\\|^{2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\sum_{i=1}^{l}\\alpha_i \\|\\phi(x_i) - h\\|^{2} = \\sum_{i=1}^{l}\\alpha_i(\\|\\phi\\|^{2} - 2\\langle \\phi(x_i), h\\rangle) + \\|h\\|^{2}(\\sum_{i=1}^{l}\\alpha_i) = \\sum_{i=1}^{l}\\alpha_i(\\|\\phi\\|^{2} - 2\\langle \\phi(x_i), h\\rangle) + \\|h\\|^{2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\|\\phi\\|^{2} = K(x_i, x_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\langle \\phi(x_i), h\\rangle = \\sum_{j=0}^{l}\\alpha_j K(x_i, x_j)\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\|h\\|^{2} = \\sum_{i=1}^{l}\\sum_{j=0}^{l}\\alpha_i \\alpha_j K(x_i, x_j)\n",
    "$$\n",
    "\n",
    "So,\n",
    "\n",
    "$$\n",
    "    \\sum_{i=1}^{l}\\alpha_i \\|\\phi(x_i) - h\\|^{2} = \\sum_{i=1}^{l}\\alpha_i(\\|\\phi\\|^{2} - 2\\langle \\phi(x_i), h\\rangle) + \\|h\\|^{2} = \\sum_{i=1}^{l}\\alpha_i K(x_i, x_i) - 2 \\sum_{i=1}^{l}\\sum_{j=0}^{l}\\alpha_i \\alpha_j K(x_i, x_j) + \\sum_{i=1}^{l}\\sum_{j=0}^{l}\\alpha_i \\alpha_j K(x_i, x_j)\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\sum_{i=1}^{l}\\alpha_i \\|\\phi(x_i) - h\\|^{2} = \\sum_{i=1}^{l}\\alpha_i K(x_i, x_i) - \\sum_{i=1}^{l}\\sum_{j=0}^{l}\\alpha_i \\alpha_j K(x_i, x_j)\n",
    "$$\n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "    L(\\alpha) = \\sum_{i=1}^{l}\\alpha_i K(x_i, x_i) - \\sum_{i=1}^{l}\\sum_{j=0}^{l}\\alpha_i \\alpha_j K(x_i, x_j) = \\sum_{i=1}^{l}\\alpha_i K(x_i, x_i) - \\alpha^{\\top}K\\alpha\n",
    "$$,\n",
    "\n",
    "where $K = \\lbrack K(x_i, x_j)\\rbrack$ is a kernel matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 (2 pt.): The dual problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Carefully eliminate $\\beta_i$ from the KKT conditions, and write\n",
    "down the inequality constraints for the dual variables $\\alpha_i$,\n",
    "implied by the FOC.\n",
    "\n",
    "* Combine your results into dual problem (minimization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's find the constraints for the dual variable $\\alpha_{i}$.<br>\n",
    "Using KKT conditions\n",
    "\n",
    "$$\n",
    "    \\frac{1}{\\nu}C_{i} - \\alpha_i - \\beta_i = 0 \\quad \\text{(The first order condition)}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "    \\beta_i \\geq 0 \\quad \\text{(dual constraint)}\n",
    "$$\n",
    "\n",
    "we will get\n",
    "\n",
    "$$\n",
    "    \\alpha_{i} \\le \\frac{1}{\\nu}C_i, \\quad i = 0, \\dots, l\n",
    "$$\n",
    "\n",
    "Since $\\alpha_i \\geq 0$ (dual constraint)\n",
    "\n",
    "$$\n",
    "    0 \\le \\alpha_{i} \\le \\frac{1}{\\nu}C_i, \\quad i = 0, \\dots, l\n",
    "$$\n",
    "\n",
    "One more constraint comes from one more first order condition\n",
    "\n",
    "$$\n",
    "    \\sum_{i=0}^{l}\\alpha_{i} = 1\n",
    "$$\n",
    "\n",
    "Now, let's define the dual problem.<br>\n",
    "\n",
    "$$\n",
    "    g(R, h, \\xi, \\alpha, \\beta) = \\inf\\limits_{R, h, \\xi} L(R, h, \\xi, \\alpha, \\beta)\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\text{maximize} \\: g\n",
    "$$\n",
    "$$\n",
    "    \\text{subject to} \\quad \\alpha \\geq 0, \\: \\beta \\geq 0\n",
    "$$\n",
    "\n",
    "In our case we will get\n",
    "\n",
    "$$\n",
    "    \\max\\limits_{\\alpha} \\bigg(\\sum_{i=1}^{l}\\alpha_i K(x_i, x_i) - \\sum_{i=1}^{l}\\sum_{j=0}^{l}\\alpha_i \\alpha_j K(x_i, x_j)\\bigg)\n",
    "$$\n",
    "$$\n",
    "    s.t. \\sum_{i=0}^{l} \\alpha_i = 1, \\quad 0 \\le \\alpha_i \\le C_i \\frac{1}{\\nu}, \\quad i = 0, \\dots, l\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6 (2 pt.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose, you have solved the dual and have optimal $(\\alpha^*_i)_{i=1}^l$ and\n",
    "$ h^* = \\sum_{i=1}^l \\alpha^*_i \\phi(x_i)$.\n",
    "\n",
    "Let $M = \\{i\\colon \\alpha^*_i \\in \\left(0, \\tfrac{C_i}{\\nu}\\right)\\}$ and suppose $M \\neq \\emptyset$.\n",
    "\n",
    "* Derive the expression for the optimal value of $R$ from this and the\n",
    "complementary sclackness conditions.\n",
    "\n",
    "* Write out the decision function for an arbitrary $x\\in \\mathcal{X}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's use here next KKT conditions\n",
    "\n",
    "$$\n",
    "    \\alpha_{i} (\\| \\phi(x_i) - h \\|^{2} - R - \\xi_i) = 0, \\quad i = 1, \\dots, l\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\beta_{i} \\xi_i = 0, \\quad i = 1, \\dots, l\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\frac{1}{\\nu}C_{i} - \\alpha_i - \\beta_i = 0, \\quad i = 1, \\dots, l\n",
    "$$\n",
    "\n",
    "Then multiplying $\\beta_i$ on the first condition we will have\n",
    "\n",
    "$$\n",
    "    \\alpha_{i}\\big(C_i\\frac{1}{\\nu} - \\alpha_{i}\\big)\\big(\\|\\phi(x_i) - h\\|^{2} - R \\big) = 0\n",
    "$$\n",
    "\n",
    "Then for optimal parameters and some $i \\in M$ we will get\n",
    "\n",
    "$$\n",
    "    \\alpha^{*}_{i}\\big(C_i\\frac{1}{\\nu} - \\alpha^{*}_{i}\\big) > 0\n",
    "$$\n",
    "\n",
    "So,\n",
    "\n",
    "$$\n",
    "    \\|\\phi(x_i) - h^{*}\\|^{2} - R = 0\n",
    "$$\n",
    "\n",
    "***We obtained the optimal value of*** $R$\n",
    "\n",
    "$$\n",
    "    R = \\|\\phi(x_i) - h^{*}\\|^{2}, \\quad \\text{for some} \\: i \\in M \\neq \\emptyset\n",
    "$$\n",
    "\n",
    "Since in the solution for the problem 4 we have obtained expression for $\\|\\phi(x_i) - h^{*}\\|^{2}$, we can easily write out the ***decision function***\n",
    "\n",
    "$$\n",
    "    f(x) = \\text{sign}\\big( R - K(x, x) + 2\\sum_{i=0}^{l}\\alpha_{i}K(x, x_{i}) - \\|h\\|^{2}\\big),\n",
    "$$\n",
    "where $R$ is optimal and $\\|h\\|^{2} = \\sum_{i=1}^{l}\\sum_{j=0}^{l}\\alpha_i \\alpha_j K(x_i, x_j)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7.1 (2 pt.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that for some $x_i$ we have $\\|\\phi(x_i) - h\\|^2 < R$.\n",
    "We will call this point **inlier**.\n",
    "\n",
    "* What are the values of $\\alpha_i$ and $\\beta_i$ for such a point?\n",
    "* Show that $1-\\nu$ upper-bounds the sum of weights $C_i$ for the **inlier** points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7.2 (2 pt.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that for some $x_i$ it holds that $\\|\\phi(x_i) - h \\|^2 > R$.\n",
    "Such points are called **outliers**.\n",
    "\n",
    "* What are the values of $\\alpha_i$ and $\\beta_i$ for these points?\n",
    "* Argue that the sum of weights $C_i$ for the **outliers** is upper bounded by $\\nu$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7.3: Very small $\\nu$ (1 pt.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that $\\nu < C_i$ for all $i=1,\\,\\ldots,\\,l$. Show that\n",
    "there are **no outliers** in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7.4 (1 pt.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose $C_i = \\tfrac1l$. Please, describe how $\\nu$ is related to the\n",
    "outliers in the datset, given the analysis above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Begin Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
